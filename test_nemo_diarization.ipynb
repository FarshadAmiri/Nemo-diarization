{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa180b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: D:\\Git_repos\\Nemo-diarization\n",
      "Python path includes: D:\\Git_repos\\Nemo-diarization\n",
      "✓ Imports successful (module reloaded)\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory to notebook location\n",
    "notebook_dir = Path(r\"D:\\Git_repos\\Nemo-diarization\")\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# Add to Python path\n",
    "if str(notebook_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(notebook_dir))\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Python path includes: {notebook_dir}\")\n",
    "\n",
    "# Reload module to get latest changes\n",
    "import importlib\n",
    "if 'nemo_diarization' in sys.modules:\n",
    "    importlib.reload(sys.modules['nemo_diarization'])\n",
    "\n",
    "# Import functions\n",
    "from nemo_diarization import diarize_with_nemo, add_transcription_to_segments, diarize_and_transcribe\n",
    "\n",
    "print(\"✓ Imports successful (module reloaded)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faafad3",
   "metadata": {},
   "source": [
    "## Create Voice Embeddings Database (Optional)\n",
    "\n",
    "If you want to identify specific speakers by name, create a database of known voices first.\n",
    "Otherwise, skip this section and speakers will be labeled as SPEAKER_00, SPEAKER_01, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdf7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Create voice embeddings database for speaker identification\n",
    "# You need reference audio samples for each person you want to identify\n",
    "# \"\"\"\n",
    "\n",
    "# # Option 1: Create database from audio samples\n",
    "# # Prepare your speaker samples - each person should have 1-3 audio clips\n",
    "# speaker_samples = {\n",
    "#     \"sp3000\": [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\3000\\15664\\3000-15664-0024.flac\", \n",
    "#                r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\3000\\15664\\3000-15664-0040.flac\"],\n",
    "#     \"sp777\" : [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\777\\126732\\777-126732-0028.flac\",\n",
    "#                r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\777\\126732\\777-126732-0025.flac\"],\n",
    "#     \"sp422\" : [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\422\\122949\\422-122949-0021.flac\",\n",
    "#                r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\422\\122949\\422-122949-0016.flac\"],\n",
    "#     \"sp1993\": [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\1993\\147964\\1993-147964-0005.flac\",\n",
    "#                r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\1993\\147964\\1993-147964-0003.flac\"],\n",
    "# }\n",
    "\n",
    "# # Database output path\n",
    "# voice_embeddings_database_path = r\"D:\\Git_repos\\Nemo-diarization\\outputs\\db\\speakers_db.json\"\n",
    "\n",
    "# # Uncomment to create the database:\n",
    "# from resemblyzer import VoiceEncoder\n",
    "# import json\n",
    "\n",
    "# encoder = VoiceEncoder()\n",
    "# embeddings_db = {}\n",
    "\n",
    "# for speaker_name, audio_files in speaker_samples.items():\n",
    "#     print(f\"Processing {speaker_name}...\")\n",
    "#     speaker_embeddings = []\n",
    "    \n",
    "#     for audio_file in audio_files:\n",
    "#         from resemblyzer import preprocess_wav\n",
    "#         wav = preprocess_wav(audio_file)\n",
    "#         embedding = encoder.embed_utterance(wav)\n",
    "#         speaker_embeddings.append(embedding.tolist())\n",
    "    \n",
    "#     # Average embeddings for better accuracy\n",
    "#     import numpy as np\n",
    "#     avg_embedding = np.mean(speaker_embeddings, axis=0)\n",
    "#     embeddings_db[speaker_name] = avg_embedding.tolist()\n",
    "#     print(f\"  ✓ {speaker_name} enrolled\")\n",
    "\n",
    "# # Save database\n",
    "# import os\n",
    "# os.makedirs(os.path.dirname(voice_embeddings_database_path), exist_ok=True)\n",
    "# with open(voice_embeddings_database_path, 'w') as f:\n",
    "#     json.dump(embeddings_db, f, indent=2)\n",
    "\n",
    "# print(f\"\\n✓ Database saved to: {voice_embeddings_database_path}\")\n",
    "# print(f\"✓ Enrolled {len(embeddings_db)} speakers\")\n",
    "\n",
    "# print(\"To create embeddings database:\")\n",
    "# print(\"1. Prepare audio samples for each speaker\")\n",
    "# print(\"2. Update the speaker_samples dictionary above\")\n",
    "# print(\"3. Uncomment the code block\")\n",
    "# print(\"4. Run this cell\")\n",
    "# print(\"\\nOr skip this if you only need anonymous speaker labels (SPEAKER_00, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c0db5",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your paths and parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e3dde2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio file to process\n",
    "meeting_audio_path = r\"D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1.wav\"\n",
    "meeting_audio_path = r\"D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1_1m.wav\"\n",
    "meeting_audio_path = r\"D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1_doubled.wav\"\n",
    "\n",
    "# Voice embeddings database (can be empty for basic diarization)\n",
    "voice_embeddings_database_path = r\"D:\\Git_repos\\Nemo-diarization\\outputs\\db\\speakers_db.json\"\n",
    "\n",
    "# Language (e.g., 'en', 'fa', 'ar', or None for auto-detect)\n",
    "expected_language = \"en\"\n",
    "\n",
    "# Whisper model for transcription ('tiny', 'base', 'small', 'medium', 'large')\n",
    "whisper_model = \"medium\"\n",
    "\n",
    "# Number of expected speakers (optional, auto-detect if None)\n",
    "num_speakers = None\n",
    "\n",
    "# Backend: use_wsl=True for NeMo (GPU), False for pyannote (Windows)\n",
    "use_wsl = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ffcf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected - PyTorch may need reinstallation with CUDA support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac928e",
   "metadata": {},
   "source": [
    "## Run Diarization\n",
    "\n",
    "NeMo diarization with GPU - completes in ~10 seconds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ecba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NVIDIA NeMo SPEAKER DIARIZATION\n",
      "======================================================================\n",
      "Audio file: D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1_doubled.wav\n",
      "Voice database: D:\\Git_repos\\Nemo-diarization\\outputs\\db\\speakers_db.json\n",
      "Mode: WSL2 NeMo GPU\n",
      "======================================================================\n",
      "\n",
      "[WSL2 Mode] Running NeMo diarization in WSL2 Ubuntu...\n",
      "Executing NeMo diarization in WSL...\n",
      "Note: First run may take longer while models download\n",
      "\n",
      "\n",
      "✓ NeMo diarization completed\n",
      "\n",
      "[Speaker Identification] Matching speakers to database...\n",
      "Loaded the voice encoder model on cuda in 0.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\venvs\\venv_nemo\\Lib\\site-packages\\resemblyzer\\voice_encoder.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Merged 25 segments → 15 segments\n",
      "\n",
      "======================================================================\n",
      "DIARIZATION RESULTS\n",
      "======================================================================\n",
      "Number of speakers: 4\n",
      "Total segments: 15\n",
      "Output files: {'rttm': '/mnt/d/Projects_tmp/noisy_audio_files/speeches/1/nemo_output/pred_rttms/concat_1_doubled.rttm'}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Diarization (fast - GPU accelerated)\n",
    "result = diarize_with_nemo(\n",
    "    meeting_audio_path=meeting_audio_path,\n",
    "    voice_embeddings_database_path=voice_embeddings_database_path,\n",
    "    num_speakers=num_speakers,\n",
    "    use_wsl=use_wsl\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIARIZATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Number of speakers: {result['num_speakers']}\")\n",
    "print(f\"Total segments: {len(result['segments'])}\")\n",
    "print(f\"Output files: {result['output_files']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0379d",
   "metadata": {},
   "source": [
    "## View Diarization Results\n",
    "\n",
    "Inspect the diarization segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fedfa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments:\n",
      "----------------------------------------------------------------------\n",
      "1. [0.54s - 20.75s] sp3000\n",
      "2. [21.18s - 33.31s] sp422\n",
      "3. [33.58s - 39.71s] sp777\n",
      "4. [39.98s - 44.10s] sp422\n",
      "5. [44.10s - 58.35s] sp3000\n",
      "6. [58.86s - 69.39s] sp777\n",
      "7. [69.74s - 82.35s] sp1993\n",
      "8. [82.86s - 116.27s] sp3000\n",
      "9. [116.78s - 128.91s] sp422\n",
      "10. [129.26s - 135.63s] sp777\n",
      "11. [135.63s - 139.79s] sp422\n",
      "12. [140.22s - 153.95s] sp3000\n",
      "13. [154.46s - 164.99s] sp777\n",
      "14. [165.34s - 177.95s] sp1993\n",
      "15. [178.46s - 191.07s] sp3000\n"
     ]
    }
   ],
   "source": [
    "# Display first 10 diarization segments\n",
    "print(\"All segments:\")\n",
    "print(\"-\" * 70)\n",
    "for i, seg in enumerate(result['segments'], 1):\n",
    "    print(f\"{i}. [{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb6be1",
   "metadata": {},
   "source": [
    "## Add Transcription\n",
    "\n",
    "Add Whisper transcription to the diarization results (runs on Windows):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "510c5de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Transcription] Loading Whisper 'medium' model on CUDA...\n",
      "[Transcription] Transcribing audio with CUDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 19122/19122 [00:29<00:00, 638.30frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transcription] Aligning with speaker segments...\n",
      "✓ Transcription complete\n",
      "✓ Detected language: en\n",
      "✓ Transcribed 44 segments, merged into 16 speech blocks\n",
      "\n",
      "======================================================================\n",
      "TRANSCRIPTION RESULTS\n",
      "======================================================================\n",
      "Detected language: en\n",
      "Transcribed segments: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Add transcription (optional - runs on Windows with Whisper)\n",
    "result = add_transcription_to_segments(\n",
    "    diarization_result=result,\n",
    "    expected_language=expected_language,\n",
    "    model_name=whisper_model\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSCRIPTION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Detected language: {result['detected_language']}\")\n",
    "print(f\"Transcribed segments: {len(result['speaker_segments'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f598a",
   "metadata": {},
   "source": [
    "## View Merged Speech (LLM-Ready Format)\n",
    "\n",
    "Perfect for generating meeting minutes with an LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69329e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGED SPEECH FOR LLM (speaker-labelled, consecutive segments merged):\n",
      "======================================================================\n",
      "('[0.00s - 20.38s] sp3000: Arctic beauty and desolation, with their blessings '\n",
      " 'and dangers, all may be found here, to test the endurance and skill of '\n",
      " 'adventurous climbers. But far better than climbing the mountain is going '\n",
      " 'around its warm, fertile base, enjoying its bounties like a bee circling '\n",
      " 'around a bank of flowers.\\n'\n",
      " '\\n'\n",
      " '[21.18s - 33.08s] sp422: The distinctions of moral values have either '\n",
      " 'originated in a ruling caste pleasantly conscious of being different from '\n",
      " 'the ruled, or among the ruled class, the slaves and dependents of all '\n",
      " 'sorts.\\n'\n",
      " '\\n'\n",
      " '[33.80s - 39.68s] sp777: Stevie, accustomed to move about disregarded, had '\n",
      " 'got up from the kitchen table carrying off his drawing to bed with him.\\n'\n",
      " '\\n'\n",
      " '[40.18s - 43.98s] sp422: We truthful ones, the nobility in ancient Greece '\n",
      " 'called themselves.\\n'\n",
      " '\\n'\n",
      " '[44.62s - 58.22s] sp3000: Perhaps the profession of doing good may be full, '\n",
      " 'but everybody should be kind at least to himself. Thus one saunters on and '\n",
      " 'on in the glorious radiance, in utter peace and forgetfulness of time.\\n'\n",
      " '\\n'\n",
      " '[59.02s - 69.16s] sp777: The sheet of paper covered with circles dropped out '\n",
      " 'of his fingers, and he remained staring at the old terrorist, as if rooted '\n",
      " 'suddenly to the spot by his morbid horror and dread of physical pain.\\n'\n",
      " '\\n'\n",
      " '[69.78s - 82.14s] sp1993: They sought about the house most of the day, as if '\n",
      " 'it were Sunday, greasing their boots, mending their suspenders, plating '\n",
      " 'whiplashes. Anyway, he would never allow one of his horses to be put to such '\n",
      " 'a strain.\\n'\n",
      " '\\n'\n",
      " '[83.00s - 116.06s] sp3000: Yet strange to say, there are days, even here, '\n",
      " 'somewhat dull looking, when the mountain seems uncommunicative, sending out '\n",
      " 'no appreciable invitation, as if not at home. Arctic beauty and desolation, '\n",
      " 'with their blessings and dangers, all may be found here, to test the '\n",
      " 'endurance and skill of adventurous climbers. But far better than climbing '\n",
      " 'the mountain is going around its warm, fertile base, enjoying its bounties '\n",
      " 'like a bee circling around a bank of flowers.\\n'\n",
      " '\\n'\n",
      " '[116.94s - 128.70s] sp422: The distinctions of moral values have either '\n",
      " 'originated in a ruling caste, pleasantly conscious of being different from '\n",
      " 'the ruled, or among the ruled class, the slaves and dependents of all '\n",
      " 'sorts.\\n'\n",
      " '\\n'\n",
      " '[129.50s - 135.38s] sp777: Stevie, accustomed to move about disregarded, had '\n",
      " 'got up from the kitchen table, carrying off his drawing to bed with him.\\n'\n",
      " '\\n'\n",
      " '[135.80s - 139.62s] sp422: We truthful ones, the nobility in ancient Greece '\n",
      " 'called themselves.\\n'\n",
      " '\\n'\n",
      " '[140.28s - 153.80s] sp3000: Perhaps the profession of doing good may be '\n",
      " 'full, but everybody should be kind at least to himself. Thus one saunters on '\n",
      " 'and on in the glorious radiance, in utter peace and forgetfulness of time.\\n'\n",
      " '\\n'\n",
      " '[154.52s - 164.74s] sp777: The sheet of paper covered with circles dropped '\n",
      " 'out of his fingers, and he remained staring at the old terraced, as if '\n",
      " 'rooted suddenly to the spot by his morbid horror and dread of physical '\n",
      " 'pain.\\n'\n",
      " '\\n'\n",
      " '[165.44s - 172.92s] sp1993: They sought about the house most of the day, as '\n",
      " 'if it were Sunday, greasing their boots, mending their suspenders, plating '\n",
      " 'whip-lashes.\\n'\n",
      " '\\n'\n",
      " '[174.00s - 177.76s] sp1993: Anyway, he would never allow one of his horses '\n",
      " 'to be put to such a strain.\\n'\n",
      " '\\n'\n",
      " '[178.56s - 190.78s] sp3000: Yet strange to say, there are days, even here, '\n",
      " 'somewhat dull-looking, when the mountain seems un-communicative, sending out '\n",
      " 'no appreciable invitation, as if not at home.')\n",
      "======================================================================\n",
      "\n",
      "✓ 16 merged speech blocks\n"
     ]
    }
   ],
   "source": [
    "# Display the merged speech text (ready for LLM input)\n",
    "from pprint import pprint\n",
    "\n",
    "if 'merged_speech_text' in result:\n",
    "    print(\"MERGED SPEECH FOR LLM (speaker-labelled, consecutive segments merged):\")\n",
    "    print(\"=\"*70)\n",
    "    pprint(result['merged_speech_text'])\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n✓ {len(result['merged_speeches'])} merged speech blocks\")\n",
    "else:\n",
    "    print(\"No transcription available. Run add_transcription_to_segments() first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de51f9d",
   "metadata": {},
   "source": [
    "## View Transcription with Speakers\n",
    "\n",
    "If transcription was enabled, view the transcribed text with speaker labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c34fdc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription with Speaker Labels:\n",
      "======================================================================\n",
      "\n",
      "[0.00s - 6.74s] sp3000:\n",
      "  Arctic beauty and desolation, with their blessings and dangers, all may be found here, to test\n",
      "\n",
      "[6.74s - 9.82s] sp3000:\n",
      "  the endurance and skill of adventurous climbers.\n",
      "\n",
      "[10.28s - 16.20s] sp3000:\n",
      "  But far better than climbing the mountain is going around its warm, fertile base, enjoying\n",
      "\n",
      "[16.20s - 20.38s] sp3000:\n",
      "  its bounties like a bee circling around a bank of flowers.\n",
      "\n",
      "[21.18s - 26.80s] sp422:\n",
      "  The distinctions of moral values have either originated in a ruling caste pleasantly conscious\n",
      "\n",
      "[26.80s - 32.14s] sp422:\n",
      "  of being different from the ruled, or among the ruled class, the slaves and dependents\n",
      "\n",
      "[32.14s - 33.08s] sp422:\n",
      "  of all sorts.\n",
      "\n",
      "[33.80s - 38.18s] sp777:\n",
      "  Stevie, accustomed to move about disregarded, had got up from the kitchen table carrying\n",
      "\n",
      "[38.18s - 39.68s] sp777:\n",
      "  off his drawing to bed with him.\n",
      "\n",
      "[40.18s - 43.98s] sp422:\n",
      "  We truthful ones, the nobility in ancient Greece called themselves.\n",
      "\n",
      "[44.62s - 50.32s] sp3000:\n",
      "  Perhaps the profession of doing good may be full, but everybody should be kind at least\n",
      "\n",
      "[50.32s - 51.04s] sp3000:\n",
      "  to himself.\n",
      "\n",
      "[51.92s - 57.50s] sp3000:\n",
      "  Thus one saunters on and on in the glorious radiance, in utter peace and forgetfulness\n",
      "\n",
      "[57.50s - 58.22s] sp3000:\n",
      "  of time.\n",
      "\n",
      "[59.02s - 63.20s] sp777:\n",
      "  The sheet of paper covered with circles dropped out of his fingers, and he remained staring\n",
      "\n",
      "[63.20s - 68.22s] sp777:\n",
      "  at the old terrorist, as if rooted suddenly to the spot by his morbid horror and dread\n",
      "\n",
      "[68.22s - 69.16s] sp777:\n",
      "  of physical pain.\n",
      "\n",
      "[69.78s - 74.42s] sp1993:\n",
      "  They sought about the house most of the day, as if it were Sunday, greasing their boots,\n",
      "\n",
      "[74.68s - 77.28s] sp1993:\n",
      "  mending their suspenders, plating whiplashes.\n",
      "\n",
      "[78.16s - 82.12s] sp1993:\n",
      "  Anyway, he would never allow one of his horses to be put to such a strain.\n"
     ]
    }
   ],
   "source": [
    "# Display transcription with speakers\n",
    "if 'speaker_segments' in result:\n",
    "    print(\"\\nTranscription with Speaker Labels:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for seg in result['speaker_segments'][:20]:  # First 20 segments\n",
    "        print(f\"\\n[{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['speaker']}:\")\n",
    "        print(f\"  {seg['text']}\")\n",
    "else:\n",
    "    print(\"Transcription not available. Set output_transcriptions=True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6e567",
   "metadata": {},
   "source": [
    "## Full Transcription Text\n",
    "\n",
    "View the complete transcribed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec7dacee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Transcription:\n",
      "======================================================================\n",
      " Arctic beauty and desolation, with their blessings and dangers, all may be found here, to test the endurance and skill of adventurous climbers. But far better than climbing the mountain is going around its warm, fertile base, enjoying its bounties like a bee circling around a bank of flowers. The distinctions of moral values have either originated in a ruling caste pleasantly conscious of being different from the ruled, or among the ruled class, the slaves and dependents of all sorts. Stevie, accustomed to move about disregarded, had got up from the kitchen table carrying off his drawing to bed with him. We truthful ones, the nobility in ancient Greece called themselves. Perhaps the profession of doing good may be full, but everybody should be kind at least to himself. Thus one saunters on and on in the glorious radiance, in utter peace and forgetfulness of time. The sheet of paper covered with circles dropped out of his fingers, and he remained staring at the old terrorist, as if rooted suddenly to the spot by his morbid horror and dread of physical pain. They sought about the house most of the day, as if it were Sunday, greasing their boots, mending their suspenders, plating whiplashes. Anyway, he would never allow one of his horses to be put to such a strain. Yet strange to say, there are days, even here, somewhat dull-looking, when the mountain seems uncommunicative, sending out no appreciable invitation, as if not at home.\n"
     ]
    }
   ],
   "source": [
    "# Display full transcription\n",
    "if 'transcription' in result:\n",
    "    print(\"Full Transcription:\")\n",
    "    print(\"=\"*70)\n",
    "    print(result['transcription'])\n",
    "else:\n",
    "    print(\"Transcription not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0b9b8",
   "metadata": {},
   "source": [
    "## All-in-One: Diarization + Transcription\n",
    "\n",
    "Or use the convenience function that does both steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncomment above to run complete pipeline in one call\n"
     ]
    }
   ],
   "source": [
    "# Complete pipeline in one call (diarization + transcription)\n",
    "# Commented out by default - uncomment to use\n",
    "# result_combined = diarize_and_transcribe(\n",
    "#     meeting_audio_path=meeting_audio_path,\n",
    "#     voice_embeddings_database_path=voice_embeddings_database_path,\n",
    "#     expected_language=expected_language,\n",
    "#     transcriptor_model_name=whisper_model,\n",
    "#     num_speakers=num_speakers,\n",
    "#     use_wsl=use_wsl\n",
    "# )\n",
    "\n",
    "# print(f\"✓ Complete! {result_combined['num_speakers']} speakers, {len(result_combined['speaker_segments'])} transcribed segments\")\n",
    "\n",
    "print(\"Uncomment above to run complete pipeline in one call\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528777ec",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Save results to different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33d6db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Results saved to: diarization_output.json\n",
      "✓ Transcript saved to: transcript_with_speakers.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save to JSON\n",
    "output_file = \"diarization_output.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✓ Results saved to: {output_file}\")\n",
    "\n",
    "# Save transcription to text file\n",
    "if 'speaker_segments' in result:\n",
    "    transcript_file = \"transcript_with_speakers.txt\"\n",
    "    with open(transcript_file, 'w', encoding='utf-8') as f:\n",
    "        for seg in result['speaker_segments']:\n",
    "            f.write(f\"[{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['speaker']}:\\n\")\n",
    "            f.write(f\"{seg['text']}\\n\\n\")\n",
    "    \n",
    "    print(f\"✓ Transcript saved to: {transcript_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204c4e3",
   "metadata": {},
   "source": [
    "## Testing with Different Whisper Models\n",
    "\n",
    "Test with your cached Whisper models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d957548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test with different models\n",
    "\n",
    "# Test with small model\n",
    "# result_small = diarize_and_transcribe(\n",
    "#     meeting_audio_path=meeting_audio_path,\n",
    "#     expected_language=\"en\",\n",
    "#     transcriptor_model_path=r\"D:\\path\\to\\whisper_small.pt\"\n",
    "# )\n",
    "\n",
    "# Test with medium model\n",
    "# result_medium = diarize_and_transcribe(\n",
    "#     meeting_audio_path=meeting_audio_path,\n",
    "#     expected_language=\"en\",\n",
    "#     transcriptor_model_path=r\"D:\\path\\to\\whisper_medium.pt\"\n",
    "# )\n",
    "\n",
    "# Test with Persian finetuned model\n",
    "# result_persian = diarize_and_transcribe(\n",
    "#     meeting_audio_path=r\"path\\to\\persian_audio.wav\",\n",
    "#     expected_language=\"fa\",\n",
    "#     transcriptor_model_path=r\"D:\\path\\to\\whisper_persian_finetuned.pt\"\n",
    "# )\n",
    "\n",
    "print(\"Uncomment the examples above to test with your cached models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
